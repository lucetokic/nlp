{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LucijaTokic\\Documents\\AA\\01 - Projects\\01 - NLP\\.paraphrasing\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "from nearpy import Engine\n",
    "from nearpy.hashes import RandomBinaryProjections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "train = pd.DataFrame(load_dataset(\"tapaco\", \"en\", split='train')) #[0:157000]\n",
    "#test = load_dataset(\"tapaco\", \"en\", split='train[157000:]')\n",
    "n = len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = train[['paraphrase_set_id', 'paraphrase']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  paraphrase_set_id               paraphrase materials  number\n",
      "0                 1        I ate the cheese.   plastic     703\n",
      "1                 1            I eat cheese.   leather     985\n",
      "2                 1     I'm eating a yogurt.     metal      86\n",
      "3                 1       I'm eating cheese.  aluminum     307\n",
      "4                 1  I'm having some cheese.  aluminum     393\n",
      "5                 1       I eat some cheese.    bamboo     740\n",
      "6                 1       I ate some cheese.      wood      93\n",
      "7                 5             It's Monday.  aluminum     776\n",
      "8                 5      It is Monday today.     stone     841\n",
      "9                 5       It's Monday today.     metal     135\n"
     ]
    }
   ],
   "source": [
    "# List of materials\n",
    "materials = pd.DataFrame({'materials': [\"glass\", \"metal\", \"wood\", \"plastic\", \"paper\", \"fabric\", \"stone\", \"ceramic\",\n",
    "                                        \"rubber\", \"leather\", \"concrete\", \"diamond\", \"silk\", \"aluminum\", \"copper\",\n",
    "                                        \"bronze\", \"silver\", \"gold\", \"bamboo\"]})\n",
    "materials_sampled = materials.sample(n, replace=True, random_state=42)\n",
    "materials_sampled = materials_sampled.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "random_numbers = pd.DataFrame({\"number\": [rd.randint(1, 1000) for _ in range(n)]})\n",
    "\n",
    "X_train_raw = pd.concat([X_train_raw, materials_sampled, random_numbers], axis=1)\n",
    "print(X_train_raw.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge columns into one\n",
    "X_train = pd.DataFrame({\"paraphrase_set_id\": X_train_raw.paraphrase_set_id, \"paraphrase_all\": X_train_raw.paraphrase})\n",
    "X_train['paraphrase_all'] = X_train_raw[X_train_raw.columns[1:]].apply(\n",
    "    lambda x: ','.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to xlsx\n",
    "#with pd.ExcelWriter(\"C:/Users/LucijaTokic/OneDrive - Clear Peaks SL/Documentos/02 - Projects/06 - ADNOC/01-NLP\"\n",
    "#                    \"/tapaco_expanded.xlsx\") as writer:\n",
    "#    X_train_raw.to_excel(writer, sheet_name=\"raw_dataset\", float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158053, 934)\n"
     ]
    }
   ],
   "source": [
    "# embedding\n",
    "tv = TfidfVectorizer(binary=False, norm=None, use_idf=False, smooth_idf=False, lowercase=True, stop_words='english',\n",
    "                     min_df=0.001, max_df=0.9, max_features=None, ngram_range=(1,1))\n",
    "X_train_emb = pd.DataFrame(tv.fit_transform(X_train.paraphrase_all).toarray())\n",
    "print(X_train_emb.shape)\n",
    "#print(X_train_emb.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LSH\n",
    "# convert it to numpy array\n",
    "embeddings_array = X_train_emb.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of our vector space\n",
    "dimension = X_train_emb.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First way: RandomBinaryProjections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random binary hash with 10 bits\n",
    "rbp = RandomBinaryProjections('rbp', 20)\n",
    "\n",
    "# Create engine with pipeline configuration\n",
    "engine = Engine(dimension, lshashes=[rbp])\n",
    "\n",
    "# Add the embeddings to the LSH engine\n",
    "for idx, embedding in enumerate(embeddings_array):\n",
    "    engine.store_vector(embedding, idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    I ate the cheese.,plastic,703\n",
      "0    I ate the cheese.,plastic,703\n",
      "0    I ate the cheese.,plastic,703\n",
      "0    I ate the cheese.,plastic,703\n",
      "0    I ate the cheese.,plastic,703\n",
      "                 ...              \n",
      "0    I ate the cheese.,plastic,703\n",
      "0    I ate the cheese.,plastic,703\n",
      "0    I ate the cheese.,plastic,703\n",
      "0    I ate the cheese.,plastic,703\n",
      "0    I ate the cheese.,plastic,703\n",
      "Name: paraphrase_all, Length: 934, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create random query vector\n",
    "neighbors = engine.neighbours(embeddings_array[10])\n",
    "#print(neighbors)\n",
    "\n",
    "# Get the index of the nearest neighbor\n",
    "nearest_neighbor_index = neighbors[0][0]\n",
    "#print(nearest_neighbor_index)\n",
    "#print(type(nearest_neighbor_index))\n",
    "\n",
    "# Retrieve the corresponding text from X_train_emb\n",
    "nearest_neighbor_text = X_train.iloc[nearest_neighbor_index]['paraphrase_all']\n",
    "\n",
    "# Print the nearest neighbor's text\n",
    "print(nearest_neighbor_text)\n",
    "#print(nearest_neighbor_text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second way: Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbits == 2\n",
      "158053 / 4 = 39513.25\n",
      "nbits == 4\n",
      "158053 / 16 = 9878.3125\n",
      "nbits == 8\n",
      "158053 / 256 = 617.39453125\n",
      "nbits == 16\n",
      "158053 / 65536 = 2.4116973876953125\n",
      "nbits == 24\n",
      "158053 / 16777216 = 0.009420692920684814\n",
      "nbits == 32\n",
      "158053 / 4294967296 = 3.6799581721425056e-05\n"
     ]
    }
   ],
   "source": [
    "for nbits in [2, 4, 8, 16, 24, 32]:\n",
    "    buckets = 1 << nbits\n",
    "    print(f\"nbits == {nbits}\")\n",
    "    print(f\"{X_train_emb.shape[0]} / {buckets} = {X_train_emb.shape[0]/buckets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the index using our vectors dimensionality (128) and nbits\n",
    "nbits = 24\n",
    "index = faiss.IndexLSH(dimension, nbits)\n",
    "# then add the data\n",
    "index.add(embeddings_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   10, 40687, 84792,   866, 57723]], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq0 = embeddings_array[10].reshape(1, dimension)\n",
    "# we use the search method to find the k nearest vectors\n",
    "D, I = index.search(xq0, k=5)\n",
    "# the indexes of these vectors are returned to I\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10                             Today is Monday.,copper,803\n",
      "40687    There's no need to go to school today.,copper,212\n",
      "84792                 She hasn't got glasses.,concrete,132\n",
      "866                        It is snowing today.,copper,645\n",
      "57723                    Is today his birthday?,copper,986\n",
      "Name: paraphrase_all, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the corresponding text from X_train_emb\n",
    "nearest_neighbor_text = X_train.iloc[I[0]]['paraphrase_all']\n",
    "# Print the nearest neighbor's text\n",
    "print(nearest_neighbor_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8345\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_raw[X_train_raw['materials'] == 'plastic']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        ],\n",
       "       [0.33333333],\n",
       "       [0.        ],\n",
       "       [0.33333333],\n",
       "       [0.33333333]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(embeddings_array[I[0]], xq0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbits = 2 --> cos = 0.414982991426106\n",
      "nbits = 4 --> cos = 0.28164965809277265\n",
      "nbits = 8 --> cos = 0.20000000000000004\n",
      "nbits = 16 --> cos = 0.20000000000000004\n",
      "nbits = 17 --> cos = 0.4877010097711745\n",
      "nbits = 18 --> cos = 0.2666666666666667\n",
      "nbits = 19 --> cos = 0.5398924451310624\n",
      "nbits = 20 --> cos = 0.4000000000000001\n",
      "nbits = 21 --> cos = 0.5116156409449846\n",
      "nbits = 22 --> cos = 0.20000000000000004\n",
      "nbits = 23 --> cos = 0.5699023252744027\n",
      "nbits = 24 --> cos = 0.6420686862090157\n",
      "nbits = 32 --> cos = 0.36710983178735745\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "for nbits in [2, 4, 8, 16, 17, 18, 19, 20, 21, 22, 23, 24, 32]:\n",
    "    index = faiss.IndexLSH(dimension, nbits)\n",
    "    index.add(embeddings_array)\n",
    "    D, I = index.search(xq0, k=k)\n",
    "    cos = cosine_similarity(embeddings_array[I[0]], xq0)\n",
    "    print(\"nbits = %d --> cos = %s\" % (nbits, np.mean(cos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([186, 139,  15, ..., 234, 119,  12], dtype=uint8)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract index binary codes (represented as int)\n",
    "arr = faiss.vector_to_array(index.codes)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(474159,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158053, 4)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# now translate them into the binary vector format\n",
    "arr_bites = (((arr[:, None] & (1 << np.arange(nbits)))) > 0).astype(int)\n",
    "print(len(arr_bites[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".paraphrasing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
